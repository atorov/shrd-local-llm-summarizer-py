{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from time import sleep\n",
    "from typing import Optional\n",
    "from requests import post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_LEN = 5000\n",
    "CHUNK_OVERLAP_LEN = 1000\n",
    "DEFAULT_ASSISTANT_MODEL = \"llama3.2\"\n",
    "DOCUMENT_FILEPATH_BASE = \"documents\"\n",
    "# DOCUMENT_FILENAME = \"qb_challenge.txt\"\n",
    "# DOCUMENT_FILENAME = \"qb_challenge_demo_transcript.txt\"\n",
    "DOCUMENT_FILENAME = \"the_three_musketeers.01-05.txt\"\n",
    "# DOCUMENT_FILENAME = \"the_three_musketeers.original.txt\"\n",
    "LEN_LIMIT = 5000\n",
    "PREVENT_OVERLOAD_PAUSE = 10  # 0 to disable\n",
    "PREVENT_OVERLOAD_PAUSE_PERIOD = 25  # 0 to disable\n",
    "SUMMARY_FILEPATH_BASE = \"results/summary\"\n",
    "SUMMARY_FILEPATH_EXT = \"txt\"\n",
    "TEM_RESULT_FILEPATH = \"results/temp_result.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_post_request(url: str, data: Optional[dict] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Make a POST request to a specified URL with optional JSON data.\n",
    "\n",
    "    :param url: The URL to which the POST request is made.\n",
    "    :param data: A dictionary containing the JSON data to be sent in the request body. Defaults to None.\n",
    "    :return: A dictionary containing the JSON response from the server.\n",
    "    \"\"\"\n",
    "    response = post(url, json=data)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(query: str, model):\n",
    "    # return prompt.rsplit(' ', 1)[0]  # Just for testing purposes\n",
    "\n",
    "    promptText = f\"\"\"\n",
    "You are a precise text summarizer. Your task is to create concise, informative summaries of any given text in no more than 3 sentences. Follow these rules strictly:\n",
    "- Capture the main idea or argument in the first sentence\n",
    "- Include the most important supporting details or evidence in the second sentence\n",
    "- Conclude with key implications, outcomes, or conclusions in the third sentence\n",
    "- If the text can be adequately summarized in fewer than 3 sentences, use fewer\n",
    "- Maintain objectivity and use clear, straightforward language\n",
    "- Preserve the original tone (academic, casual, technical) while remaining concise\n",
    "- Do not introduce new information not present in the original text\n",
    "- Format the summary as a single paragraph\n",
    "- Do not include any other explanation or context except the summary itself\n",
    "- Do not include any introductory text, nor concluding sentences, nor outroductory text, like \"Here is the text with the requested formatting:\"\n",
    "Following the rules described above, please summarize the following text:\n",
    "<text>\n",
    "{query}\n",
    "</text>\n",
    "\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": promptText,\n",
    "        \"stream\": False,\n",
    "    }\n",
    "\n",
    "    completion = make_post_request(\n",
    "        url=\"http://localhost:11434/api/generate\", data=data)[\"response\"]\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    Load the contents of a document from a specified file path.\n",
    "\n",
    "    :param filepath: The path to the file to be read.\n",
    "    :return: The text content of the file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_to_file(text: str, filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Save a string of text to a specified file path.\n",
    "\n",
    "    :param text: The text to be saved.\n",
    "    :param filepath: The path to the file to be written.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text: str, chunk_size: int, overlap_size: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split a text into chunks of a specified size with a specified overlap.\n",
    "\n",
    "    :param text: The input text to be split into chunks.\n",
    "    :param chunk_size: The size of each chunk.\n",
    "    :param overlap_size: The number of characters that overlap between consecutive chunks.\n",
    "    :return: A list of text chunks.\n",
    "    \"\"\"\n",
    "    chunks: list[str] = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap_size\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_document(document_filepath: str, chunk_len=CHUNK_LEN, overlap_len=CHUNK_OVERLAP_LEN, len_limit=LEN_LIMIT) -> list[str]:\n",
    "    \"\"\"\n",
    "    Summarize a document by splitting it into chunks and processing each chunk iteratively until the total length is within the specified limit.\n",
    "\n",
    "    :param document_filepath: The path to the document to be summarized.\n",
    "    :param chunk_len: The length of each chunk.\n",
    "    :param overlap_len: The length of the overlap between consecutive chunks.\n",
    "    :param len_limit: The maximum allowed length of the summarized document.\n",
    "    :return: A list of summarized text chunks.\n",
    "    \"\"\"\n",
    "    # Read the contents of the document\n",
    "    content = load_doc(document_filepath)\n",
    "\n",
    "    # Initial split of the document into chunks\n",
    "    chunks = split_text_into_chunks(content, chunk_len, overlap_len)\n",
    "\n",
    "    # Check the total length of the initial chunks\n",
    "    total_len = sum(len(chunk) for chunk in chunks)\n",
    "    if total_len <= len_limit:\n",
    "        return ''.join(chunks)  # TODO: just return the original text\n",
    "\n",
    "    # Iteratively process and concatenate chunks until the total length is within the limit\n",
    "    iter_count = 0\n",
    "    while True:\n",
    "        iter_count += 1\n",
    "        print(f\"::: Iteration {iter_count} :::\")\n",
    "        print(f\"::: Total length of chunks: {len(chunks)}\")\n",
    "        print(\n",
    "            f\"::: Total length of concatenated chunks: {sum(len(chunk) for chunk in chunks)}\")\n",
    "\n",
    "        # List to store processed chunks in the current iteration\n",
    "        processed_chunks = []\n",
    "\n",
    "        # Process each chunk\n",
    "        chunk_iter = 0\n",
    "        for chunk in chunks:\n",
    "            chunk_iter += 1\n",
    "            print(\n",
    "                f\"::: Processing chunk {iter_count}-{chunk_iter}/{len(chunks)}...\")\n",
    "            processed_chunk = generate_completion(query=chunk, model=DEFAULT_ASSISTANT_MODEL)\n",
    "            # print(f\"::: Processed chunk {processed_chunk}\")\n",
    "            processed_chunks.append(processed_chunk)\n",
    "\n",
    "            # Sleep for 5 seconds to avoid overloading the server (optional) - can be adjusted  or disabled in the configuration section above \n",
    "            if PREVENT_OVERLOAD_PAUSE != 0 and PREVENT_OVERLOAD_PAUSE_PERIOD != 0 and chunk_iter % PREVENT_OVERLOAD_PAUSE_PERIOD == 0:\n",
    "                print(\n",
    "                    f\"::: Pausing for {PREVENT_OVERLOAD_PAUSE} seconds...\")\n",
    "                sleep(PREVENT_OVERLOAD_PAUSE)\n",
    "\n",
    "        # Concatenate all processed chunks into a single string\n",
    "        concatenated_chunks = ''.join(processed_chunks)\n",
    "        save_text_to_file(concatenated_chunks, TEM_RESULT_FILEPATH)\n",
    "\n",
    "        # Check if the total length of concatenated chunks is below the limit\n",
    "        if len(concatenated_chunks) <= len_limit:\n",
    "            break\n",
    "\n",
    "        # Re-split concatenated text into overlapping chunks for the next iteration\n",
    "        chunks = split_text_into_chunks(\n",
    "            concatenated_chunks, chunk_len, overlap_len)\n",
    "\n",
    "    return '  ø ' + '\\n\\n  ø '.join(processed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: Iteration 1 :::\n",
      "::: Total length of chunks: 3\n",
      "::: Total length of concatenated chunks: 10562\n",
      "::: Processing chunk 1-1/3...\n",
      "::: Processing chunk 1-2/3...\n",
      "::: Processing chunk 1-3/3...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "::: Final Summary $  ø Here is the summary of the text:\n",
      "\n",
      "The speaker presents their experience with creating a QuickBase app to track product inventory in a warehouse. The app automates inventory management by reducing stock levels based on sales, and includes features such as color-coding for different regions and reports for order status and performance data.\n",
      "\n",
      "Key implications are that the app provides valuable insights into inventory levels and order status, allowing managers to make informed decisions about supply and demand, and enables companies to streamline their operations and improve customer satisfaction.\n",
      "\n",
      "  ø Veselin Petrov demonstrates a Quickbase platform-based AI assistant that can fetch data from the platform and provide answers to questions. The AI assistant uses preloaded prompts and real-time data to respond with relatively accurate answers, significantly reducing incorrect responses, but its capabilities are still limited by its experimental stage. This demo showcases the power of the Quickbase platform in building such an assistant quickly and efficiently.\n",
      "\n",
      "  ø The speakers discuss the integration of new content into some stories, with no specific details provided about the content or context. Some participants, such as Petrov and Gupta, express agreement or confirmation about the integration, while others, like Haas, show appreciation but also end their participation early. The conversation ultimately concludes with a sense of closure, as various individuals bid farewell to the meeting. :::\n"
     ]
    }
   ],
   "source": [
    "document_filepath = f\"{DOCUMENT_FILEPATH_BASE}/{DOCUMENT_FILENAME}\"\n",
    "summaryText = summarize_document(document_filepath=document_filepath)\n",
    "\n",
    "escapedFilename = sub(r'\\W+', '_', DOCUMENT_FILENAME)\n",
    "escapedModelname = sub(r'\\W+', '', DEFAULT_ASSISTANT_MODEL)\n",
    "summary_filepath = f\"{SUMMARY_FILEPATH_BASE}_{escapedFilename}_{escapedModelname}_{CHUNK_LEN}_{CHUNK_OVERLAP_LEN}_{LEN_LIMIT}.{SUMMARY_FILEPATH_EXT}\"\n",
    "save_text_to_file(summaryText, summary_filepath)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "print(f\"::: Final Summary ${summaryText} :::\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
