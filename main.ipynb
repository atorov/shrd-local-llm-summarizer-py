{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from time import sleep\n",
    "from typing import Optional\n",
    "from requests import post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_LEN = 5000\n",
    "CHUNK_OVERLAP_LEN = 1000\n",
    "DEFAULT_ASSISTANT_MODEL = \"qwen3\"\n",
    "DOCUMENT_FILEPATH_BASE = \"documents\"\n",
    "# DOCUMENT_FILENAME = \"test.txt\"\n",
    "DOCUMENT_FILENAME = \"the_three_musketeers.01-05.txt\"\n",
    "LEN_LIMIT = 5000\n",
    "PREVENT_OVERLOAD_PAUSE = 10  # 0 to disable\n",
    "PREVENT_OVERLOAD_PAUSE_PERIOD = 25  # 0 to disable\n",
    "SUMMARY_FILEPATH_BASE = \"results/summary\"\n",
    "SUMMARY_FILEPATH_EXT = \"txt\"\n",
    "TEM_RESULT_FILEPATH = \"results/temp_result.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_post_request(url: str, data: Optional[dict] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Make a POST request to a specified URL with optional JSON data.\n",
    "\n",
    "    :param url: The URL to which the POST request is made.\n",
    "    :param data: A dictionary containing the JSON data to be sent in the request body. Defaults to None.\n",
    "    :return: A dictionary containing the JSON response from the server.\n",
    "    \"\"\"\n",
    "    response = post(url, json=data)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(query: str, model):\n",
    "    # return prompt.rsplit(' ', 1)[0]  # Just for testing purposes\n",
    "\n",
    "    promptText = f\"\"\"\n",
    "You are a precise text summarizer. Your task is to create concise, informative summaries of any given text in no more than 3 sentences. Follow these rules strictly:\n",
    "- Capture the main idea or argument in the first sentence\n",
    "- Include the most important supporting details or evidence in the second sentence\n",
    "- Conclude with key implications, outcomes, or conclusions in the third sentence\n",
    "- If the text can be adequately summarized in fewer than 3 sentences, use fewer\n",
    "- Maintain objectivity and use clear, straightforward language\n",
    "- Preserve the original tone (academic, casual, technical) while remaining concise\n",
    "- Do not introduce new information not present in the original text\n",
    "- Format the summary as a single paragraph\n",
    "- Do not include any other explanation or context except the summary itself\n",
    "- Do not include any introductory text, nor concluding sentences, nor outroductory text, like \"Here is the text with the requested formatting:\"\n",
    "Following the rules described above, please summarize the following text:\n",
    "<text>\n",
    "{query}\n",
    "</text>\n",
    "\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": promptText,\n",
    "        \"stream\": False,\n",
    "    }\n",
    "\n",
    "    completion = make_post_request(\n",
    "        url=\"http://localhost:11434/api/generate\", data=data)[\"response\"]\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filepath: str) -> str:\n",
    "    \"\"\"\n",
    "    Load the contents of a document from a specified file path.\n",
    "\n",
    "    :param filepath: The path to the file to be read.\n",
    "    :return: The text content of the file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_to_file(text: str, filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Save a string of text to a specified file path.\n",
    "\n",
    "    :param text: The text to be saved.\n",
    "    :param filepath: The path to the file to be written.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text: str, chunk_size: int, overlap_size: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split a text into chunks of a specified size with a specified overlap.\n",
    "\n",
    "    :param text: The input text to be split into chunks.\n",
    "    :param chunk_size: The size of each chunk.\n",
    "    :param overlap_size: The number of characters that overlap between consecutive chunks.\n",
    "    :return: A list of text chunks.\n",
    "    \"\"\"\n",
    "    chunks: list[str] = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap_size\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_document(document_filepath: str, chunk_len=CHUNK_LEN, overlap_len=CHUNK_OVERLAP_LEN, len_limit=LEN_LIMIT) -> list[str]:\n",
    "    \"\"\"\n",
    "    Summarize a document by splitting it into chunks and processing each chunk iteratively until the total length is within the specified limit.\n",
    "\n",
    "    :param document_filepath: The path to the document to be summarized.\n",
    "    :param chunk_len: The length of each chunk.\n",
    "    :param overlap_len: The length of the overlap between consecutive chunks.\n",
    "    :param len_limit: The maximum allowed length of the summarized document.\n",
    "    :return: A list of summarized text chunks.\n",
    "    \"\"\"\n",
    "    # Read the contents of the document\n",
    "    content = load_doc(document_filepath)\n",
    "\n",
    "    # Initial split of the document into chunks\n",
    "    chunks = split_text_into_chunks(content, chunk_len, overlap_len)\n",
    "\n",
    "    # Check the total length of the initial chunks\n",
    "    total_len = sum(len(chunk) for chunk in chunks)\n",
    "    if total_len <= len_limit:\n",
    "        return ''.join(chunks)  # TODO: just return the original text\n",
    "\n",
    "    # Iteratively process and concatenate chunks until the total length is within the limit\n",
    "    iter_count = 0\n",
    "    while True:\n",
    "        iter_count += 1\n",
    "        print(f\"::: Iteration {iter_count} :::\")\n",
    "        print(f\"::: Total length of chunks: {len(chunks)}\")\n",
    "        print(\n",
    "            f\"::: Total length of concatenated chunks: {sum(len(chunk) for chunk in chunks)}\")\n",
    "\n",
    "        # List to store processed chunks in the current iteration\n",
    "        processed_chunks = []\n",
    "\n",
    "        # Process each chunk\n",
    "        chunk_iter = 0\n",
    "        for chunk in chunks:\n",
    "            chunk_iter += 1\n",
    "            print(\n",
    "                f\"::: Processing chunk {iter_count}-{chunk_iter}/{len(chunks)}...\")\n",
    "            processed_chunk = generate_completion(query=chunk, model=DEFAULT_ASSISTANT_MODEL)\n",
    "            # print(f\"::: Processed chunk {processed_chunk}\")\n",
    "            processed_chunks.append(processed_chunk)\n",
    "\n",
    "            # Sleep for 5 seconds to avoid overloading the server (optional) - can be adjusted  or disabled in the configuration section above \n",
    "            if PREVENT_OVERLOAD_PAUSE != 0 and PREVENT_OVERLOAD_PAUSE_PERIOD != 0 and chunk_iter % PREVENT_OVERLOAD_PAUSE_PERIOD == 0:\n",
    "                print(\n",
    "                    f\"::: Pausing for {PREVENT_OVERLOAD_PAUSE} seconds...\")\n",
    "                sleep(PREVENT_OVERLOAD_PAUSE)\n",
    "\n",
    "        # Concatenate all processed chunks into a single string\n",
    "        concatenated_chunks = ''.join(processed_chunks)\n",
    "        save_text_to_file(concatenated_chunks, TEM_RESULT_FILEPATH)\n",
    "\n",
    "        # Check if the total length of concatenated chunks is below the limit\n",
    "        if len(concatenated_chunks) <= len_limit:\n",
    "            break\n",
    "\n",
    "        # Re-split concatenated text into overlapping chunks for the next iteration\n",
    "        chunks = split_text_into_chunks(\n",
    "            concatenated_chunks, chunk_len, overlap_len)\n",
    "\n",
    "    return '  ø ' + '\\n\\n  ø '.join(processed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: Iteration 1 :::\n",
      "::: Total length of chunks: 30\n",
      "::: Total length of concatenated chunks: 147599\n",
      "::: Processing chunk 1-1/30...\n",
      "::: Processing chunk 1-2/30...\n",
      "::: Processing chunk 1-3/30...\n",
      "::: Processing chunk 1-4/30...\n",
      "::: Processing chunk 1-5/30...\n",
      "::: Processing chunk 1-6/30...\n",
      "::: Processing chunk 1-7/30...\n",
      "::: Processing chunk 1-8/30...\n",
      "::: Processing chunk 1-9/30...\n",
      "::: Processing chunk 1-10/30...\n",
      "::: Processing chunk 1-11/30...\n",
      "::: Processing chunk 1-12/30...\n",
      "::: Processing chunk 1-13/30...\n",
      "::: Processing chunk 1-14/30...\n",
      "::: Processing chunk 1-15/30...\n",
      "::: Processing chunk 1-16/30...\n",
      "::: Processing chunk 1-17/30...\n",
      "::: Processing chunk 1-18/30...\n",
      "::: Processing chunk 1-19/30...\n",
      "::: Processing chunk 1-20/30...\n",
      "::: Processing chunk 1-21/30...\n",
      "::: Processing chunk 1-22/30...\n",
      "::: Processing chunk 1-23/30...\n",
      "::: Processing chunk 1-24/30...\n",
      "::: Processing chunk 1-25/30...\n",
      "::: Pausing for 10 seconds...\n",
      "::: Processing chunk 1-26/30...\n",
      "::: Processing chunk 1-27/30...\n",
      "::: Processing chunk 1-28/30...\n",
      "::: Processing chunk 1-29/30...\n",
      "::: Processing chunk 1-30/30...\n",
      "::: Iteration 2 :::\n",
      "::: Total length of chunks: 4\n",
      "::: Total length of concatenated chunks: 15858\n",
      "::: Processing chunk 2-1/4...\n",
      "::: Processing chunk 2-2/4...\n",
      "::: Processing chunk 2-3/4...\n",
      "::: Processing chunk 2-4/4...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "::: Final Summary $  ø *The Three Musketeers* introduces D’Artagnan’s early adventures in 17th-century France, blending historical turmoil with his quest for recognition as a Musketeer. His arrival in Meung, marked by a comically unrefined Béarn pony and attire, sparks mockery and sets up his trials to prove his worth through courage and ambition. The narrative intertwines personal conflict, a stolen letter, and encounters with figures like M. de Tréville, shaping D’Artagnan’s path toward courtly influence and loyalty-driven heroism.\n",
      "\n",
      "  ø M. de Tréville’s control over the undisciplined yet fiercely loyal Musketeers solidified his power and influence at King Louis XIII’s court. Their chaotic reputation for instigating conflicts and serving Tréville’s interests contrasted with their role as both protectors and agents of political intrigue. D’Artagnan’s struggle to gain entry into the elite corps and the Musketeers’ internal tensions underscore the perilous, scandalous dynamics of courtly power struggles.\n",
      "\n",
      "  ø D’Artagnan pursues entry into the Musketeers despite stolen letters and suspicions of espionage, navigating conflicts with Tréville and rival Musketeers. His impulsive actions, including duels with Athos, Porthos, and Aramis, and a handkerchief dispute, highlight his recklessness and social awkwardness. The Musketeers’ eventual victory over royalist forces and D’Artagnan’s resolve to defy authority solidify his place in the brotherhood.\n",
      "\n",
      "  ø D’Artagnan’s declaration of allegiance solidifies the Musketeers’ resolve to confront royalist forces. The group defeats key adversaries through duels, with D’Artagnan outmaneuvering Jussac and Bicarat surrendering after a prolonged struggle. Their victory secures their position and marks D’Artagnan’s formal induction into the Musketeer brotherhood. :::\n"
     ]
    }
   ],
   "source": [
    "document_filepath = f\"{DOCUMENT_FILEPATH_BASE}/{DOCUMENT_FILENAME}\"\n",
    "summaryText = summarize_document(document_filepath=document_filepath)\n",
    "\n",
    "escapedFilename = sub(r'\\W+', '_', DOCUMENT_FILENAME)\n",
    "escapedModelname = sub(r'\\W+', '', DEFAULT_ASSISTANT_MODEL)\n",
    "summary_filepath = f\"{SUMMARY_FILEPATH_BASE}_{escapedFilename}_{escapedModelname}_{CHUNK_LEN}_{CHUNK_OVERLAP_LEN}_{LEN_LIMIT}.{SUMMARY_FILEPATH_EXT}\"\n",
    "save_text_to_file(summaryText, summary_filepath)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "print(f\"::: Final Summary ${summaryText} :::\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
